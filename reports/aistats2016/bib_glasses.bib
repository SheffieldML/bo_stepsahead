@book{Rasmussen:2005:GPM:1162254,
 author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
 title = {Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)},
 year = {2005},
 publisher = {The MIT Press},
} 

@article{gonzalez2014,
  title={Bayesian Optimisation for synthetic gene design},
  author={Gonz\'alez, Javier and Longworth, Joseph and James, David and Lawrence, Neil},
  journal={NIPS Workshop on Bayesian Optimization in Academia and Industry},
  year = {2014}
}
@article{Huang:2006,
 author = {Huang, D. and Allen, T. T. and Notz, W. I. and Zeng, N.},
 title = {Global Optimization of Stochastic Black-Box Systems via Sequential Kriging Meta-Models},
 journal = {J. of Global Optimization},
 issue_date = {March 2006},
 volume = {34},
 number = {3},
 month = mar,
 year = {2006},
 issn = {0925-5001},
 pages = {441--466},
 numpages = {26},
 acmid = {1120199},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Efficient global optimization, expected improvement, kriging, stochastic black-box systems},
} 


@article{Nocedal1980,
    author = {Nocedal, Jorge},
    citeulike-article-id = {1284223},
    journal = {Mathematics of Computation},
    keywords = {maxent, quality},
    number = {151},
    pages = {773--782},
    posted-at = {2007-05-08 21:42:02},
    priority = {2},
    title = {{Updating Quasi-Newton Matrices with Limited Storage}},
    volume = {35},
    year = {1980}
}

@article{Jones1993,
 author = {Jones, D. R. and Perttunen, C. D. and Stuckman, B. E.},
 title = {Lipschitzian Optimization Without the Lipschitz Constant},
 journal = {J. Optim. Theory Appl.},
 issue_date = {Oct. 1993},
 volume = {79},
 number = {1},
 month = oct,
 year = {1993},
 issn = {0022-3239},
 pages = {157--181},
 numpages = {25},
 acmid = {173678},
 publisher = {Plenum Press},
 address = {New York, NY, USA},
} 

@article{gonzalez2015batch,
  title={Batch Bayesian Optimization via Local Penalization},
  author={Gonz{\'a}lez, Javier and Dai, Zhenwen and Hennig, Philipp and Lawrence, Neil D},
  journal={arXiv preprint arXiv:1505.08052},
  year={2015}
}

@incollection{NIPS2012_4577,
title = {Near-Optimal MAP Inference for Determinantal Point Processes},
author = {Jennifer Gillenwater and Kulesza, Alex and Taskar, Ben},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C.J.C. Burges and L. Bottou and K.Q. Weinberger},
pages = {2735--2743},
year = {2012},
publisher = {Curran Associates, Inc.},
}

@article{MAL-044,
year = {2012},
volume = {5},
journal = {Foundations and Trends® in Machine Learning},
title = {Determinantal Point Processes for Machine Learning},
doi = {10.1561/2200000044},
issn = {1935-8237},
number = {2–3},
pages = {123-286},
author = {Alex Kulesza and Ben Taskar}
}

@INPROCEEDINGS{Affandi:NIPS2013,
    author={Affandi, R.H. and Fox, E.B. and Taskar, B.},
    title={Approximate Inference in Continuous Determinantal Processes},
    booktitle = "Neural Information Processing Systems 26",
    year = {2014},
    publisher = {MIT Press},
    }

@inproceedings{KuleszaT11,
  added-at = {2011-12-16T00:00:00.000+0100},
  author = {Kulesza, Alex and Taskar, Ben},
  booktitle = {ICML},
  crossref = {conf/icml/2011},
  editor = {Getoor, Lise and Scheffe},
  year = {2011},
  }

@article{StreltsovVakili1999,
    author = {Streltsov, Simon and Vakili, Pirooz},
    citeulike-article-id = {9223491},
    journal = {J. Global Optim.},
    keywords = {stochasticprogramming},
    number = {3},
    pages = {283--298},
    posted-at = {2011-04-28 18:44:26},
    priority = {2},
    title = {{A non-myopic utility function for statistical global optimization algorithms}},
    volume = {14},
    year = {1999}
}


@inproceedings{Minka:2001,
 author = {Minka, Thomas P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence},
 series = {UAI '01},
 year = {2001},
 isbn = {1-55860-800-1},
 pages = {362--369},
 numpages = {8},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 


@phdthesis{osborne_bayesian_2010,
  title = {Bayesian {Gaussian} {Processes} for {Sequential} {Prediction}, {Optimisation} and {Quadrature}},
  school = {PhD thesis, University of Oxford},
  author = {Osborne, Michael},
  year = {2010},
}


@book{Rasmussen:2005:GPM:1162254,
 author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
 title = {Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)},
 year = {2005},
 publisher = {The MIT Press},
} 

@inproceedings{Marchant*Ramos*Sanner*2014,
    title={Sequential {B}ayesian Optimisation for Spatial-Temporal Monitoring},
    Booktitle = {Proceedings of the International Conference on Uncertainty in Artificial Intelligence},
    year={2014},
    author={Marchant, Roman and Ramos, Fabio and Sanner, Scott}
}

@inproceedings{osborne_gaussian_2009,
  title = {{G}aussian processes for global optimization},
  booktitle = {3rd international conference on learning and intelligent optimization ({LION}3)},
  author = {Osborne, Michael A. and Garnett, Roman and Roberts, Stephen J.},
  year = {2009},
  pages = {1--15}
}

@article{Cunningham*Hennig*Lacoste-Julien_2011,
  title={{G}aussian Probabilities and Expectation Propagation},
  note={arXiv: 1111.6832},
  journal={arXiv:1111.6832 [stat]},
  author={Cunningham, John P. and Hennig, Philipp and Lacoste-Julien, Simon},
  year={2011},
  month={Nov}
}

@article{Borodin*Rains*2005,
title={{Eynard–Mehta} Theorem, {Schur} Process, and their {Pfaffian} Analogs},
volume={121},
DOI={10.1007/s10955-005-7583-z},
number={3-4},
journal={Journal of Statistical Physics},
author={Borodin, Alexei and Rains, Eric M.},
year={2005},
month={Nov},
pages={291–317}}

@article{Ginsbourger2009,
title={A multi-points criterion for deterministic parallel global optimization based on {G}aussian processes},
journal={HAL: hal-00260579},
author={Ginsbourger, David and Le Riche, Rodolphe and Carraro, Laurent},
year={2009}}

@inproceedings{Azimi2012,
  author    = {Javad Azimi and
               Ali Jalali and
               Xiaoli Zhang Fern},
  title     = {Hybrid Batch {B}ayesian Optimization},
  booktitle = {Proceedings of the 29th International Conference on Machine Learning},
  year      = {2012}
}

@article{Azimi2011,
  author    = {Javad Azimi and
               Ali Jalali and
               Xiaoli Fern},
  title     = {Dynamic Batch {B}ayesian Optimization},
  journal   = {CoRR},
  volume    = {abs/1110.3347},
  year      = {2011}
}



@article{Brochu*Cora*DeFreitas_2010,
title={A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning},
journal={arXiv preprint arXiv:1012.2599},
author={Brochu, Eric and Cora, Vlad M. and De Freitas, Nando},
year={2010}}

@article{Snoek*Rippel*Swersky*Kiros*Satish*Sundaram*Patwary*Prabhat*Adams_2,
title={Scalable Bayesian Optimization Using Deep Neural Networks},
url={http://arxiv.org/abs/1502.05700},
note={arXiv: 1502.05700},
journal={arXiv:1502.05700 [stat]},
author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Md Mostofa Ali and Prabhat and Adams, Ryan P.},
year={2014}}

@inbook{Snoek*Larochelle*Adams_2012,
title={Practical Bayesian optimization of machine learning algorithms},
booktitle={Advances in Neural Information Processing Systems},
author={Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
year={2012},
pages={2951–2959}}

@article{Jones_2001,
title={A taxonomy of global optimization methods based on response surfaces},
volume={21},
number={4},
journal={Journal of global optimization},
author={Jones, Donald R.},
year={2001},
pages={345–383}}

@phdthesis{Lizotte_2008,
place={Edmonton, Alta., Canada},
title={Practical
Bayesian Optimization},
note={AAINR46365},
school={University of Alberta},
author={Lizotte, Daniel James},
year={2008}}

@inbook{Garnett*Osborne*Roberts_2010,
title={Bayesian optimization for sensor
set selection}, ISBN={1605589888}, DOI={10.1145/1791212.1791238},
abstractNote={We consider the problem of selecting an optimal set of sensors,
as determined, for example, by the predictive accuracy of the resulting sensor
network. Given an underlying metric between pairs of set elements, we
introduce a natural metric between sets of sensors for this task. Using this
metric, we can construct covariance functions over sets, and thereby perform
Gaussian process inference over a function whose domain is a power set. If the
function has additional inputs, our covariances can be readily extended to
incorporate them—allowing us to consider, for example, functions over both
sets and time. These functions can then be optimized using Gaussian process
global optimization (GPGO). We use the root mean squared error (RMSE) of the
predictions made using a set of sensors at a particular time as an example of
such a function to be optimized; the optimal point specifies the best choice
of sensor locations. We demonstrate the resulting method by dynamically
selecting the best subset of a given set of weather sensors for the prediction
of the air temperature across the United Kingdom.}, booktitle={Proceedings of
the 9th ACM/IEEE International Conference on Information Processing in Sensor
Networks}, publisher={ACM}, author={Garnett, R. and Osborne, M. A. and
Roberts, S. J.}, year={2010}, pages={209–219}}


@article{martinez-cantin_bayesian_2009,
  title = {A {Bayesian} exploration-exploitation approach for optimal online sensing and planning with a visually guided mobile robot},
  volume = {27},
  issn = {0929-5593, 1573-7527},
  doi = {10.1007/s10514-009-9130-2},
  abstract = {We address the problem of online path planning for optimal sensing with a mobile robot. The objective of the robot is to learn the most about its pose and the environment given time constraints. We use a POMDP with a utility function that depends on the belief state to model the finite horizon planning problem. We replan as the robot progresses throughout the environment. The POMDP is high-dimensional, continuous, non-differentiable, nonlinear, non-Gaussian and must be solved in real-time. Most existing techniques for stochastic planning and reinforcement learning are therefore inapplicable. To solve this extremely complex problem, we propose a Bayesian optimization method that dynamically trades off exploration (minimizing uncertainty in unknown parts of the policy space) and exploitation (capitalizing on the current best solution). We demonstrate our approach with a visually-guide mobile robot. The solution proposed here is also applicable to other closely-related domains, including active vision, sequential experimental design, dynamic sensing and calibration with mobile sensors.},
  language = {en},
  number = {2},
  urldate = {2015-05-25},
  journal = {Autonomous Robots},
  author = {Martinez-Cantin, Ruben and Freitas, Nando de and Brochu, Eric and Castellanos, José and Doucet, Arnaud},
  month = aug,
  year = {2009},
  keywords = {Active learning, Active SLAM, Active vision, Artificial Intelligence (incl. Robotics), Attention and gaze planning, Bayesian optimization, Computer Imaging, Vision, Pattern Recognition and Graphics, Control , Robotics, Mechatronics, Dynamic sensor networks, Electrical Engineering, Mechanical Engineering, Model predictive control, Online path planning, Policy search, Reinforcement learning, Sequential experimental design, Simulation and Modeling},
  pages = {93--103},
}
